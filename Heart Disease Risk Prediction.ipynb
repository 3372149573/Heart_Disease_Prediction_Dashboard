{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f9bf2-ff49-4dff-9e69-dc701f13e573",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/praji/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Heart Disease Risk Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3fc46-cb57-43e4-9cdf-220a09d38eb6",
   "metadata": {},
   "source": [
    "## Objective\n",
    "### The goal of this project is to build a machine learning model that predicts the likelihood of heart disease based on patient health metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6877c25-0286-4dcd-bc5e-6e3c014a6282",
   "metadata": {},
   "source": [
    "### Importing required libraries for the Machine Learning Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb62a3-b273-4857-95ee-9703f46fb322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a09a51-9b09-4b8e-a91a-6d5c6b668ecf",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12815da-4315-4df1-a8c2-1cf718578ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffc6cd-ba22-4dc7-bbb6-62f37657708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdda587-d604-4454-b6f8-672e91a5afed",
   "metadata": {},
   "source": [
    "### Checking numbers of rows and columns in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781a85c6-a52d-4369-8c48-d605f7247f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbcc94d-d9f1-4d8e-9e91-b28630673289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aada83-20ab-41a0-8443-c3de3f9d0503",
   "metadata": {},
   "source": [
    "### Checking for Missing or Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca737b5b-cc52-407b-bda8-efd144c70dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df == 0.0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335489e9-f7b6-4e50-bda5-cff3809261b0",
   "metadata": {},
   "source": [
    "### Exploring Data Types and Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3e640-e814-4c0c-b0f4-abdb2a21fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9870339-70db-4542-9535-60205d564176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16c1b1-7162-499e-8054-bb9a15e019f7",
   "metadata": {},
   "source": [
    "### Visualizes how categorical features relate to heart disease. For example, the sex countplot shows the number of males and females with or without heart disease, helping identify patterns and important features for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211f0e2-5266-4b66-9539-2271a3ac5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sex', hue='target', data=df, palette='coolwarm')\n",
    "plt.title(\"Sex vs Heart Disease\")\n",
    "plt.xticks([0,1], ['Female','Male'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4aa46-3ce7-49be-8e48-90f25484779f",
   "metadata": {},
   "source": [
    "### Correlation Heatmap\n",
    "#### Shows how features are correlated with each other and with the target.\n",
    "\n",
    "#### Helps in understanding which features may be more important for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ffb666-9476-474a-9949-c03622feddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap of Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46162af3-c8b9-488f-91a4-b005f8db44bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins = 50, figsize = (20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e40feb-ee76-45cd-95b1-822e90f7848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df == 0.0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b4577-edbc-46f3-9e1d-88a9ef5578de",
   "metadata": {},
   "source": [
    "### Handling Missing/Zero Values\n",
    "#### Replaces 0 values in cholesterol with the median of non-zero cholesterol values.\n",
    "\n",
    "#### This avoids biasing the model with invalid zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262ecb4-f6d7-47a5-bacf-e91128971408",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cholesterol = df[df['cholesterol'] > 0] ['cholesterol'].median()\n",
    "print(median_cholesterol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb6d77-7a56-4f6c-bf8c-7ae1ac235cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cholesterol'] = df['cholesterol'].replace(0, median_cholesterol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64942c08-ae83-46b9-8000-8b79e264b8da",
   "metadata": {},
   "source": [
    "finding data where their values is 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ae292-05e0-4ca4-a228-69f4583d3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df == 0.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e69fe-f82d-4292-80d0-fc473dd5b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap of Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42e5e-996d-4851-ab61-4cc1e7129282",
   "metadata": {},
   "source": [
    "### Dropping Less Useful Features ie, negative correlated columns \n",
    "#### Keeps the dataset clean and reduces noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6eb893-4e23-4489-9aa5-15c134c3226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop([ 'resting bp s', 'cholesterol',\n",
    "               'fasting blood sugar', 'resting ecg', 'max heart rate'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896da611-b785-488b-ae82-86c8d4bcd431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056fa07e-4a79-4c36-a7b4-d6b446c4ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df1.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap of Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd46b008-b26c-4684-b42a-8f7ba67434bd",
   "metadata": {},
   "source": [
    "### Checking Data Distribution\n",
    "#### Prints the distribution of values for each column.\n",
    "#### Helps understand categorical feature balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82182fcf-9850-40b5-9b8a-f3e53aeae806",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df1.columns:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(df1[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341d0c8-d7fb-4288-be49-e8d3921c17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2357e6-5e05-4413-94e1-426853aeccc8",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "#### Splits the data into training set (80%) and testing set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b916d-3719-4dea-845f-48855995b8f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1.drop('target', axis=1)\n",
    "y = df1['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=45, stratify=y  # stratify keeps balance\n",
    ")\n",
    "\n",
    "print(\"Train target distribution:\\n\", y_train.value_counts())\n",
    "print(\"Test target distribution:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80445c-910b-4987-8eba-747987415ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['sex', 'chest pain type', 'exercise angina', 'ST slope','oldpeak']:\n",
    "    print(f\"\\n{col} - Train:\")\n",
    "    print(X_train[col].value_counts(normalize=True))\n",
    "    print(f\"{col} - Test:\")\n",
    "    print(X_test[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe39acf-0c60-4e71-904d-962143cd045b",
   "metadata": {},
   "source": [
    "### Handling Negative Values\n",
    "#### Replaces negative values in oldpeak with 0.\n",
    "\n",
    "#### Negative values are invalid in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aab98a-d8f7-4325-9ade-916315c9da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['oldpeak'] = X['oldpeak'].apply(lambda x: 0 if x < 0 else x)\n",
    "X_train['oldpeak'] = X_train['oldpeak'].apply(lambda x: 0 if x < 0 else x)\n",
    "X_test['oldpeak']  = X_test['oldpeak'].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836150fb-6d5f-4086-8456-bf0efdbc2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1['oldpeak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd74cfd-582e-43a5-8b1d-e315b44339c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['oldpeak']:\n",
    "    print(f\"\\n{col} - Train:\")\n",
    "    print(X_train[col].value_counts(normalize=True))\n",
    "    print(f\"{col} - Test:\")\n",
    "    print(X_test[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc4e99-61ed-4cf9-9cbb-961572d88509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_train = X_train.copy()\n",
    "df1_train['target'] = y_train\n",
    "df1_test = X_test.copy()\n",
    "df1_test['target'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3375f9e-e052-451a-bb3c-393b95e9d3e4",
   "metadata": {},
   "source": [
    "### Comparing Feature Distribution in Train vs Test\n",
    "#### Plots bar charts for selected categorical features (sex, chest pain type, exercise angina, ST slope) to verify that train and test distributions are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb85ce-b64c-4d39-9f9a-8ec8a1089bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sex', 'chest pain type', 'exercise angina', 'ST slope']\n",
    "\n",
    "for col in cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    train_counts = df1_train[col].value_counts(normalize=True).sort_index()\n",
    "    test_counts  = df1_test[col].value_counts(normalize=True).sort_index()\n",
    "    df_plot = pd.DataFrame({'Train': train_counts, 'Test': test_counts})\n",
    "    df_plot.plot(kind='bar', figsize=(8,4))\n",
    "    plt.title(f'Train vs Test Distribution: {col}')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xlabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4baefc-d12f-4974-bbe4-eab90d22dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),      \n",
    "    ('model', LogisticRegression())    \n",
    "])\n",
    "\n",
    "# Train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb8b56-a16c-465c-808d-d3a4104f8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Pipeline\n",
    "pipe_dt = Pipeline([\n",
    "    ('scaler', StandardScaler()),         \n",
    "    ('dt', DecisionTreeClassifier(random_state=45))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "pipe_dt.fit(X_train[cols], y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_dt = pipe_dt.predict(X_test[cols])\n",
    "\n",
    "# Evaluate\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e799bac-2081-4fa8-aedb-429d704d001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # optional for tree-based models\n",
    "    ('rf', RandomForestClassifier(n_estimators=900, random_state=45))\n",
    "])\n",
    "\n",
    "# Train\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = pipe_rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d952bf3-00c0-4c9b-8f63-65b66186bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Linear Regression pipeline\n",
    "pipe_lr_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train\n",
    "pipe_lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = pipe_lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_lr))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred_lr))\n",
    "\n",
    "y_pred_lr_bin = (y_pred_lr >= 0.5).astype(int)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Linear Regression Accuracy (binary):\", accuracy_score(y_test, y_pred_lr_bin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c6d7f3-e12d-4c8d-bf48-49d31139655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN pipeline\n",
    "pipe_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # scaling is important for KNN\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))  # you can tune n_neighbors\n",
    "])\n",
    "\n",
    "# Train\n",
    "pipe_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_knn = pipe_knn.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99192f-e560-4014-ba05-426777afde33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=1000,    # number of trees\n",
    "    learning_rate=0.10,   # step size shr\n",
    "    max_depth=4,         # depth of each tree\n",
    "    random_state=45\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea6a54-1454-4d86-b0d8-7e486e0ccd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Create a dictionary to store your models and predictions\n",
    "models_preds = {\n",
    "    'Logistic Regression': y_pred,\n",
    "    'Decision Tree': y_pred_dt,\n",
    "    'Random Forest': y_pred_rf,\n",
    "    'Linear Regression (binary)': y_pred_lr_bin,\n",
    "    'K-Nearest Neighbors': y_pred_knn,\n",
    "    'Gradient Boosting': y_pred_gb\n",
    "}\n",
    "\n",
    "# Initialize a list to store metrics\n",
    "metrics_list = []\n",
    "\n",
    "# Calculate metrics for each model\n",
    "for model_name, preds in models_preds.items():\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    \n",
    "    \n",
    "    \n",
    "    metrics_list.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': round(accuracy, 3),\n",
    "        'Precision': round(precision, 3),\n",
    "        'Recall': round(recall, 3),\n",
    "        'F1-score': round(f1, 3),\n",
    "        \n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df = metrics_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59133f-1d74-48e9-906d-311de519843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# --- 1. Accuracy Table and Bar Plot ---\n",
    "accuracy_dict = {\n",
    "    'Logistic Regression': accuracy_score(y_test, y_pred),\n",
    "    'Decision Tree': accuracy_score(y_test, y_pred_dt),\n",
    "    'Random Forest': accuracy_score(y_test, y_pred_rf),\n",
    "    'Linear Regression (binary)': accuracy_score(y_test, y_pred_lr_bin),\n",
    "    'K-Nearest Neighbors': accuracy_score(y_test, y_pred_knn),\n",
    "    'Gradient Boosting': accuracy_score(y_test, y_pred_gb)\n",
    "}\n",
    "\n",
    "accuracy_table = pd.DataFrame(list(accuracy_dict.items()), columns=['Model', 'Accuracy']).sort_values(by='Accuracy', ascending=False)\n",
    "print(accuracy_table)\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='Accuracy', y='Model', data=accuracy_table, palette='viridis')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlim(0,1)\n",
    "plt.show()\n",
    "\n",
    "# --- 3. ROC Curves ---\n",
    "models_proba = {\n",
    "    'Logistic Regression': pipeline,\n",
    "    'Random Forest': pipe_rf,\n",
    "    'Gradient Boosting': gb_model,\n",
    "    'K-Nearest Neighbors': pipe_knn\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for name, model in models_proba.items():\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)[:,1]  \n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC={roc_auc:.2f})')\n",
    "    except:\n",
    "        print(f'{name} skipped (no predict_proba)')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e0edf-117e-4c17-af27-554e9dce58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_conf_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['No Disease', 'Disease'],\n",
    "                yticklabels=['No Disease', 'Disease'])\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for your models:\n",
    "plot_conf_matrix(y_test, y_pred, \"Logistic Regression\")\n",
    "plot_conf_matrix(y_test, y_pred_dt, \"Decision Tree\")\n",
    "plot_conf_matrix(y_test, y_pred_rf, \"Random Forest\")\n",
    "plot_conf_matrix(y_test, y_pred_lr_bin, \"Linear Regression (Binary)\")\n",
    "plot_conf_matrix(y_test, y_pred_knn, \"KNN\")\n",
    "plot_conf_matrix(y_test, y_pred_gb, \"Gradient Boosting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00b6ed-1159-4a9f-a0bb-29edd70f7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x_feature = 'age'\n",
    "y_feature = 'chest pain type'\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df[df['target']==0][x_feature], df[df['target']==0][y_feature],\n",
    "            color='blue', label='No (0)', alpha=0.6, edgecolor='k')\n",
    "\n",
    "plt.scatter(df[df['target']==1][x_feature], df[df['target']==1][y_feature],\n",
    "            color='red', label='Yes (1)', alpha=0.6, edgecolor='k')\n",
    "\n",
    "plt.xlabel(x_feature)\n",
    "plt.ylabel(y_feature)\n",
    "plt.title(f\"Scatter Plot of {x_feature} vs {y_feature}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71004942-d53a-40e1-ab10-0d9c2621b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99c269-088f-4902-9d06-064021aa4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Run this in your Jupyter Notebook\n",
    "# ============================================\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have:\n",
    "# - df: your heart disease dataframe\n",
    "# - gb_model: your trained Gradient Boost model\n",
    "# - X: your features dataframe\n",
    "# - y: your target variable\n",
    "\n",
    "# ============================================\n",
    "# 1. SAVE THE TRAINED MODEL\n",
    "# ============================================\n",
    "\n",
    "# Save your trained Gradient Boost model\n",
    "joblib.dump(gb_model, \"heart_model.pkl\")\n",
    "print(\"‚úÖ Model saved as 'heart_model.pkl'\")\n",
    "\n",
    "# ============================================\n",
    "# 2. SAVE HEALTHY AVERAGE VALUES\n",
    "# ============================================\n",
    "\n",
    "# Calculate average values for healthy patients (target == 0)\n",
    "# Using only the 6 features we need for prediction\n",
    "features_needed = ['age', 'sex', 'chest pain type', 'exercise angina', 'oldpeak', 'ST slope']\n",
    "\n",
    "healthy_avg = df[df['target'] == 0][features_needed].mean()\n",
    "\n",
    "# Convert to dictionary format\n",
    "healthy_avg_dict = healthy_avg.to_dict()\n",
    "\n",
    "# Save as JSON\n",
    "import json\n",
    "with open('healthy_avg.json', 'w') as f:\n",
    "    json.dump([healthy_avg_dict], f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Healthy averages saved as 'healthy_avg.json'\")\n",
    "print(\"\\nHealthy Average Values:\")\n",
    "print(healthy_avg_dict)\n",
    "\n",
    "# ============================================\n",
    "# 3. VERIFY THE SAVED FILES\n",
    "# ============================================\n",
    "\n",
    "# Test loading the model\n",
    "loaded_model = joblib.load(\"heart_model.pkl\")\n",
    "print(\"\\n‚úÖ Model loaded successfully\")\n",
    "\n",
    "# Test prediction with sample data\n",
    "sample_data = np.array([[55, 1, 3, 1, 2.5, 2]])  # Example values\n",
    "prediction = loaded_model.predict(sample_data)\n",
    "prediction_proba = loaded_model.predict_proba(sample_data)\n",
    "\n",
    "print(f\"\\nüß™ Test Prediction:\")\n",
    "print(f\"   Prediction: {prediction[0]}\")\n",
    "print(f\"   Probability: {prediction_proba[0]}\")\n",
    "\n",
    "# Check if model has feature_importances_\n",
    "if hasattr(loaded_model, 'feature_importances_'):\n",
    "    print(\"\\n‚úÖ Feature importances available\")\n",
    "    feature_names = ['Age', 'Sex', 'Chest Pain Type', 'Exercise Angina', 'Oldpeak', 'ST Slope']\n",
    "    for name, importance in zip(feature_names, loaded_model.feature_importances_):\n",
    "        print(f\"   {name}: {importance:.4f}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Model doesn't have feature_importances_\")\n",
    "\n",
    "# ============================================\n",
    "# 4. VERIFY JSON FILE\n",
    "# ============================================\n",
    "\n",
    "with open('healthy_avg.json', 'r') as f:\n",
    "    loaded_avg = json.load(f)\n",
    "print(\"\\n‚úÖ Healthy averages loaded successfully:\")\n",
    "print(loaded_avg)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üì¶ FILES READY FOR DEPLOYMENT:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. heart_model.pkl - Place in: backend/model/\")\n",
    "print(\"2. healthy_avg.json - Place in: backend/model/\")\n",
    "print(\"\\nYou can now move these files to your Django backend!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1aad8-c358-4298-ada4-10246e659a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Save your trained model (assuming gb_model is your trained model)\n",
    "joblib.dump(gb_model, \"heart_model.pkl\")\n",
    "\n",
    "# Save healthy averages (assuming df is your dataframe)\n",
    "features_needed = ['age', 'sex', 'chest pain type', 'exercise angina', 'oldpeak', 'ST slope']\n",
    "healthy_avg = df[df['target'] == 0][features_needed].mean()\n",
    "with open('healthy_avg.json', 'w') as f:\n",
    "    json.dump([healthy_avg.to_dict()], f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Files created: heart_model.pkl and healthy_avg.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576298f-3cea-4432-ad77-1523fe1c7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sklearn\n",
    "\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "\n",
    "# Re-save your model (replace 'gb_model' with your actual model variable)\n",
    "joblib.dump(gb_model, \"heart_model.pkl\")\n",
    "print(\"‚úÖ Model re-saved with current scikit-learn version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0941a-b960-4328-ba1e-a4d03a2fbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('Jupyter scikit-learn:', sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4c1b0-d637-4087-ae08-a16581101adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Check version\n",
    "import sklearn\n",
    "print('scikit-learn version:', sklearn.__version__)\n",
    "\n",
    "# Load your data (adjust column names if needed)\n",
    "# df = pd.read_csv('your_heart_disease_data.csv')\n",
    "\n",
    "# Train your model again (use your actual training code)\n",
    "# Example:\n",
    "# X = df[['age', 'sex', 'chest pain type', 'exercise angina', 'oldpeak', 'ST slope']]\n",
    "# y = df['target']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# gb_model = GradientBoostingClassifier(random_state=42)\n",
    "# gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the newly trained model\n",
    "joblib.dump(gb_model, \"model.pkl\")\n",
    "print(\"‚úÖ Model saved!\")\n",
    "\n",
    "# Save healthy averages\n",
    "features_needed = ['age', 'sex', 'chest pain type', 'exercise angina', 'oldpeak', 'ST slope']\n",
    "healthy_avg = df[df['target'] == 0][features_needed].mean()\n",
    "\n",
    "with open('healthy_avg.json', 'w') as f:\n",
    "    json.dump([healthy_avg.to_dict()], f, indent=4)\n",
    "print(\"‚úÖ Healthy averages saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1be0d-93c2-46b4-b724-e0b935c98fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('numpy version:', numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c4615-4076-4845-810e-ba0ba0eb4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
